# SER
Speech Emotion Recognition 
As human beings, speech is amongst the most
natural ways to express ourselves. We depend so much on it
that we recognize its importance when resorting to other
communication forms like emails and text messages. As we use
more voice-controlled gadgets, emotion recognition will be an
integral part of these devices in the near future. Emotion
detection is a challenging task, because emotions are subjective.
There is no common consensus on how to measure or
categorize them. This paper proposes a model to recognize
emotions from speech based on a multilayer perceptron
network and making use of the functionalities of MFCC, MEL,
and Chroma to recognize the emotion of the audio input.
Experiments indicate that the model proposed in this paper can
excellently predict speech emotion.
